{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Machine_Hack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOt0/kR7A5em3R2DZNNmJF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwarajShinde/Multi-Label-Classification-Bert/blob/master/Sentiment_Machine_Hack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w4zwJRShvv9",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mexg62-NhIx2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4a021c4a-96a4-4509-cbd3-f5d59bea63f8"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import regex as re\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59jPlV09hf_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "86ca8160-e25e-4510-d9be-bdffaecc8700"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQoqcKJ0h3DY",
        "colab_type": "text"
      },
      "source": [
        "Config :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv0v4yMCia7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvWbKPJXywKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42e09f93-4df3-4dde-b80a-bb8bf9eacb50"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXLx4f91i0ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv('/content/Sample Submission.csv')\n",
        "train = pd.read_csv(\"/content/Train.csv\")\n",
        "test = pd.read_csv(\"/content/Test.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_d8-JgqjREc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ax = train.loc[:,'Product_Description']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY5TKIagjkbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3a9476e2-9f38-4f42-9c14-59e70c24a9fc"
      },
      "source": [
        "for i in range(5):\n",
        "    print(ax[i])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Web DesignerÛªs Guide to iOS (and Android) Apps, today @mention 10 a.m! {link} #sxsw\n",
            "RT @mention Line for iPad 2 is longer today than yesterday. #SXSW  // are you getting in line again today just for fun?\n",
            "Crazy that Apple is opening a temporary store in Austin tomorrow to handle the rabid #sxsw eye pad too seekers.\n",
            "The lesson from Google One Pass: In this digital environment, users want to purchase across every platform with one tool. #sxsw #elonsxsw\n",
            "RT @mention At the panel: &quot;Your mom has an ipad, designing for boomers&quot; #sxsw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6W44afMkZrt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "859a3cb3-f8a4-492b-c29a-e89a71ae20c1"
      },
      "source": [
        "sns.countplot(train['Sentiment'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5e91a02d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAnTk3pIlMUr",
        "colab_type": "text"
      },
      "source": [
        "Skewed Label Classes \n",
        "Startified K-fold for CV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Pz91eZkiJm",
        "colab_type": "text"
      },
      "source": [
        "** Text Cleaning Is Required **\n",
        "\n",
        "Regex Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k9OQ8aPlBOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "def remove_punctuation(text):\n",
        "    removed_punct = [ word for word in text if word not in string.punctuation]\n",
        "    final_word = \"\".join(removed_punct)\n",
        "    return final_word \n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmwhUrmal-nZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['review'] = train['Product_Description'].apply(lambda x: remove_punctuation(x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVnjH1ComCeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop('Product_Description',axis=1,inplace=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYH5zJ1Rpa_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5a2315a2-1b3c-4026-8b8f-bc8cb06035c6"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Product_Type</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3057</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>The Web DesignerÛªs Guide to iOS and Android ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6254</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>RT mention Line for iPad 2 is longer today tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8212</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>Crazy that Apple is opening a temporary store ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4422</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>The lesson from Google One Pass In this digita...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5526</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>RT mention At the panel quotYour mom has an ip...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Text_ID  ...                                             review\n",
              "0     3057  ...  The Web DesignerÛªs Guide to iOS and Android ...\n",
              "1     6254  ...  RT mention Line for iPad 2 is longer today tha...\n",
              "2     8212  ...  Crazy that Apple is opening a temporary store ...\n",
              "3     4422  ...  The lesson from Google One Pass In this digita...\n",
              "4     5526  ...  RT mention At the panel quotYour mom has an ip...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBfHyZDmnEdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['review'] = test['Product_Description'].apply(lambda x: remove_punctuation(x))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crEbQmgMPm_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a74d51d1-2ad8-442f-c2a9-ea70e4d92d24"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6364, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDAA8SCvnOKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop(\"Product_Description\",axis=1,inplace=True)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MU8dHWeepgCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop('Text_ID',axis=1,inplace=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2WuG89ryqgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "b04f77bb-418b-47a0-b533-e7d2eb79f9c2"
      },
      "source": [
        "token_lens=[]\n",
        "\n",
        "for text in train.review:\n",
        "    tok = tokenizer.encode(text)\n",
        "    token_lens.append(len(tok))\n",
        "\n",
        "sns.distplot(token_lens)\n",
        "print(max(token_lens))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6SnVuBm-11P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "bert_path = 'bert-base-uncased'\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained(bert_path,do_lower_case=True)\n",
        "MAX_LEN = 64\n",
        "train_batch_size = 8\n",
        "valid_batch_size = 4\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gyiGpLs-Rox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDataset(Dataset):\n",
        "    def __init__(self,reviews,targets):\n",
        "        self.reviews=reviews\n",
        "        self.tokenizer = tokenizer\n",
        "        self.targets = targets # have a doubt over this \n",
        "        self.max_len = MAX_LEN\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        review = str(self.reviews[item])\n",
        "      #  review = \"\".join(review.split())\n",
        "        inputs = self.tokenizer.encode_plus( \n",
        "            review,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation = True\n",
        "        )\n",
        "        target = self.targets[item]\n",
        "\n",
        "\n",
        "        ids =  inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "\n",
        "\n",
        "        return {\n",
        "            'review_text':review,\n",
        "            'ids':inputs['input_ids'].flatten(),\n",
        "            'mask':inputs['attention_mask'].flatten(),\n",
        "            'target':torch.tensor(target,dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nhiChq8PUQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train,df_valid = train_test_split(train,test_size=0.1,random_state=42,stratify = train['Sentiment'])\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1il-1DkKDbQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_valid = df_valid.reset_index(drop=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUT4ctCLsSLR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs2xLzn-Dmbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = BertDataset(reviews=df_train.review.values,targets=df_train.Sentiment.values)\n",
        "valid_dataset = BertDataset(reviews=df_valid.review.values,targets=df_valid.Sentiment.values)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=train_batch_size,num_workers=4)\n",
        "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch_size,num_workers=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AninwJyC0bJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "e949e5db-a0e9-49ff-e694-9f5d8917f880"
      },
      "source": [
        "# Example Batch :\n",
        "\n",
        "exam = next(iter(train_dataloader))\n",
        "exam.keys()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'ids', 'mask', 'target'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1VE3Rv12jSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "17c7c07b-4c6a-4490-cf91-22b370c068bc"
      },
      "source": [
        "print(exam['ids'].shape)\n",
        "print(exam['mask'].shape)\n",
        "print(exam['target'].shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 64])\n",
            "torch.Size([8, 64])\n",
            "torch.Size([8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UYwGDjh289X",
        "colab_type": "text"
      },
      "source": [
        "Now till here we can infer that our DataLoader/Dataset is working FINE ...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6yaPa7bE8Cr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertModel,self).__init__()\n",
        "        self.bert = transformers.BertModel.from_pretrained(bert_path)\n",
        "        self.drop = nn.Dropout(0.1)\n",
        "        self.out = nn.Linear(768,4)\n",
        "        \n",
        "    def forward(self,ids,mask):\n",
        "        _,o2 = self.bert(ids,attention_mask=mask)\n",
        "        bo = self.drop(o2)\n",
        "        output = self.out(bo)\n",
        "        return output"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-RjgKfXGlJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertModel()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTp58hTsCA24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(DEVICE)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XttSt_IJG8vR",
        "colab_type": "text"
      },
      "source": [
        "Move all to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvkqfJ8VMXY_",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "1.   LEARN TO USE TQDM\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTZzz-X0GsbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f5cea71-3282-4b72-ac78-dfc699d5b1f2"
      },
      "source": [
        "# EXAMPLE :\n",
        "ids = exam['ids'].to(DEVICE)\n",
        "mask = exam['mask'].to(DEVICE)\n",
        "print(ids.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC1L9hU4CxlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c506ea4a-2b7d-43f1-d90c-80fc03cb660d"
      },
      "source": [
        "x= (model(ids,mask))\n",
        "#print(model(ids,mask))\n",
        "print(x)\n",
        "#print(x.shape)\n",
        "torch.max(x,dim=1\n",
        "          )"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.0419, -2.3395,  3.8415, -0.5955],\n",
            "        [-0.8687, -2.5651, -0.9116,  5.2733],\n",
            "        [-1.8754, -3.9308,  3.6802,  1.7517],\n",
            "        [-1.9340, -3.8975,  3.8293,  2.0463],\n",
            "        [-1.9291, -3.8285,  3.4014,  1.8849],\n",
            "        [-0.9461, -2.6454, -0.9023,  5.0187],\n",
            "        [-1.8419, -3.9053,  4.2601,  1.6035],\n",
            "        [ 0.2037,  0.8619,  1.5382, -3.4882]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([3.8415, 5.2733, 3.6802, 3.8293, 3.4014, 5.0187, 4.2601, 1.5382],\n",
              "       device='cuda:0', grad_fn=<MaxBackward0>), indices=tensor([2, 3, 2, 2, 2, 3, 2, 2], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLcObkGdH50F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss().to(DEVICE)\n",
        "epochs = 5\n",
        "optimizer =  AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaZP1zIhIdif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fn(data_loader,model,optimizer,loss_fn,device,scheduler,n_examples):\n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    tkt = tqdm(data_loader,total = len(data_loader))\n",
        "    for d in tkt:\n",
        "        ids = d['ids'].to(device)\n",
        "        mask = d['mask'].to(device)\n",
        "        targets = d['target'].to(device)\n",
        "\n",
        "        outputs = model(ids=ids,mask=mask)\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        loss = loss_fn(outputs,targets)\n",
        "\n",
        "        correct_predictions += torch.sum(preds==targets)\n",
        "        losses.append(loss.item())\n",
        "    \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    #print(f\"Individual Training Losses {loss.item()} \" )\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGRN4bFjI1tU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_fn(data_loader,model,device,loss_fn,n_examples):\n",
        "    model = model.eval()\n",
        "    losses= []\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        tke = tqdm(data_loader,total = len(data_loader))\n",
        "        for d in tke:\n",
        "            ids = d['ids'].to(device)\n",
        "            mask = d['mask'].to(device)\n",
        "            targets = d['target'].to(device)\n",
        "\n",
        "            outputs = model(ids=ids,mask=mask)\n",
        "            _,preds = torch.max(outputs,dim=1)\n",
        "\n",
        "            loss = loss_fn(outputs,targets)\n",
        "\n",
        "\n",
        "            correct_predictions += torch.sum(preds == targets)\n",
        "            losses.append(loss.item())\n",
        "           # print(f\"Individual Evaluation Losses {loss.item()} \" )\n",
        "\n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jeuAVwYKVhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6QF44kkF0q8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZAIA-JoKXGK",
        "colab_type": "text"
      },
      "source": [
        "Now the Almighty Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqSTK5frKQbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "\n",
        "    history = defaultdict(list)\n",
        "    best_accuracy = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1} /{epochs}\")\n",
        "        print('-' * 10)\n",
        "        \n",
        "\n",
        "        train_acc,train_loss = train_fn(train_dataloader,model,optimizer,loss_fn,DEVICE,scheduler,len(df_train))\n",
        "        \n",
        "        print(f\"Training Losses {train_loss} accuracy {train_acc}\")\n",
        "        \n",
        "\n",
        "        eval_acc,eval_loss = eval_fn(valid_dataloader,model,DEVICE,loss_fn,len(df_valid))\n",
        "\n",
        "        print(f'Val loss {eval_loss} accuracy {eval_acc}')\n",
        "        print()\n",
        "\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['eval_acc'].append(eval_acc)\n",
        "        history['eval_loss'].append(eval_loss)\n",
        "\n",
        "        if eval_acc > best_accuracy:\n",
        "            torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "            best_accuracy = eval_acc\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2HHSUTzLPMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5bb82b60-3ade-400d-ada6-77f58bc1b8d5"
      },
      "source": [
        "run()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/716 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 /5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 716/716 [00:53<00:00, 13.46it/s]\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Losses 0.8602318079861183 accuracy 0.6245852977125894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 160/160 [00:02<00:00, 66.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.8016556500457227 accuracy 0.6248037676609105\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/716 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 /5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 716/716 [00:53<00:00, 13.50it/s]\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Losses 0.6260975821973891 accuracy 0.753448576916361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 160/160 [00:02<00:00, 66.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.8070500325877219 accuracy 0.6624803767660911\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/716 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 /5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 716/716 [00:52<00:00, 13.52it/s]\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Losses 0.41157614385615515 accuracy 0.8505325650427797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 160/160 [00:02<00:00, 65.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 0.9261689843609929 accuracy 0.6640502354788069\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/716 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 /5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 716/716 [00:53<00:00, 13.50it/s]\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Losses 0.28854329029472764 accuracy 0.8990745591059891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 160/160 [00:02<00:00, 67.19it/s]\n",
            "  0%|          | 0/716 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 1.0703456054790876 accuracy 0.6483516483516484\n",
            "\n",
            "Epoch 5 /5\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 716/716 [00:52<00:00, 13.52it/s]\n",
            "  0%|          | 0/160 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training Losses 0.2144544015654139 accuracy 0.9280600663523659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "100%|██████████| 160/160 [00:02<00:00, 66.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val loss 1.1595388233603443 accuracy 0.6624803767660911\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BvUuc6gLQLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Time to perform Inference"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZBrrk2qaoMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.Dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lldPq8-tax55",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd34b0c5-f550-4995-d6d2-ebd99ac3779e"
      },
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "'''"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom google.colab import drive\\ndrive.mount(\"/content/drive\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHlb9jE6a0bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/content/best_model_state.bin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQvkmYsZbdEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "45e877b3-7ef4-478b-cbda-e3922c7c8490"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Product_Type</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5786</td>\n",
              "      <td>7</td>\n",
              "      <td>RT mention Going to SXSW The new iPhone guide ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5363</td>\n",
              "      <td>9</td>\n",
              "      <td>RT mention 95 of iPhone and Droid apps have le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6716</td>\n",
              "      <td>9</td>\n",
              "      <td>RT mention Thank you to mention for letting me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4339</td>\n",
              "      <td>7</td>\n",
              "      <td>Thanks mention were lovin the mention app upda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66</td>\n",
              "      <td>9</td>\n",
              "      <td>At sxsw mention  mention wanna buy you a drink...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Text_ID  Product_Type                                             review\n",
              "0     5786             7  RT mention Going to SXSW The new iPhone guide ...\n",
              "1     5363             9  RT mention 95 of iPhone and Droid apps have le...\n",
              "2     6716             9  RT mention Thank you to mention for letting me...\n",
              "3     4339             7  Thanks mention were lovin the mention app upda...\n",
              "4       66             9  At sxsw mention  mention wanna buy you a drink..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2CzR-tWwKMr",
        "colab_type": "text"
      },
      "source": [
        "** Inference **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JkqHVqP0Lpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertDataset_test(Dataset):\n",
        "    def __init__(self,reviews):\n",
        "        self.reviews=reviews\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = MAX_LEN\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        review = str(self.reviews[item])\n",
        "        inputs = self.tokenizer.encode_plus( \n",
        "            review,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "            truncation = True\n",
        "        )\n",
        "\n",
        "\n",
        "        ids =  inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "\n",
        "\n",
        "\n",
        "        return {\n",
        "            'review_text':review,\n",
        "            'ids':inputs['input_ids'].flatten(),\n",
        "            'mask':inputs['attention_mask'].flatten()\n",
        "        }"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcKPFEzaFZPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = BertDataset_test(test.review.values)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMaiurQVFn5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataloader = DataLoader(test_df,batch_size=4,num_workers=2)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOPaFFwy0GAC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking Whether the Bottleneck is Dataloader or the trainnig Loop itself\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80UCq2sS0Opg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a8f00b05-388d-46c1-c509-056653b7f0a0"
      },
      "source": [
        "example = next(iter(test_dataloader))\n",
        "example.keys()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'ids', 'mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRYEOlLy0VX3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "504ae27b-c0d2-4274-a96f-81dd2abcc856"
      },
      "source": [
        "print(example['ids'].shape)\n",
        "print(example['ids'].shape)\n",
        "print(example['mask'].shape)\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 64])\n",
            "torch.Size([4, 64])\n",
            "torch.Size([4, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPQ5Smiy1c6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ex_ids = example['ids'].to(DEVICE)\n",
        "ex_mask = example['mask'].to(DEVICE)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUzKl9f41nS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = F.softmax(model(ex_ids,ex_mask),dim=1)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPq40tEV10Hi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8543d314-0210-40de-d0a3-2b535ad71610"
      },
      "source": [
        "print(y)\n",
        "torch.max(y,axis=1)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.4041e-03, 2.4591e-04, 2.8603e-03, 9.9549e-01],\n",
            "        [4.6622e-02, 9.4327e-01, 8.6560e-03, 1.4546e-03],\n",
            "        [5.7570e-03, 1.6359e-03, 9.8272e-01, 9.8836e-03],\n",
            "        [3.0183e-03, 5.6878e-04, 1.5976e-01, 8.3666e-01]], device='cuda:0',\n",
            "       grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([0.9955, 0.9433, 0.9827, 0.8367], device='cuda:0',\n",
              "       grad_fn=<MaxBackward0>), indices=tensor([3, 1, 2, 3], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y30EEPZN2Nc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# So here we confirm that out dataLoader is not our Bottle neck"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cd9zwoiGf8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#torch.save(model.state_dict(), '/content/drive/My Drive/best_model_state.bin')\n"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aeO-cfa2Yow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(DEVICE)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msRqO6Ro2ef_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hope so the weights loaded are the weights of the best model\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLOTAdZbGvu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create Testing Loop \n",
        "test[\"sentiment\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBnTh14zG3JO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_fn(model,dataloader,device,):\n",
        "    model.eval()\n",
        "    final_pred = []\n",
        "    with torch.no_grad():\n",
        "        tk0 = tqdm(test_dataloader,total=len(test_dataloader))\n",
        "        for data in tk0:\n",
        "            ids = data['ids'].to(device)\n",
        "            mask = data['mask'].to(device)\n",
        "            op = model(ids,mask)\n",
        "            _,preds = torch.max(op,dim=1)\n",
        "            # if want the probability dont use max()\n",
        "            final_pred.append(preds.tolist())\n",
        "\n",
        "    return final_pred\n",
        "\n",
        "    "
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmG7z6YUIEJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f9836c2-5df2-4030-dfac-7529d0b7f572"
      },
      "source": [
        "axes = test_fn(model,test_dataloader,DEVICE)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/682 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "\n",
            "\n",
            "  0%|          | 1/682 [00:00<01:13,  9.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "  1%|          | 8/682 [00:00<00:53, 12.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "  2%|▏         | 15/682 [00:00<00:40, 16.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "  3%|▎         | 23/682 [00:00<00:30, 21.59it/s]\u001b[A\u001b[A\n",
            "\n",
            "  4%|▍         | 30/682 [00:00<00:24, 27.09it/s]\u001b[A\u001b[A\n",
            "\n",
            "  5%|▌         | 37/682 [00:00<00:19, 33.08it/s]\u001b[A\u001b[A\n",
            "\n",
            "  6%|▋         | 44/682 [00:00<00:16, 38.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "  7%|▋         | 51/682 [00:00<00:14, 44.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "  9%|▊         | 59/682 [00:00<00:12, 50.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 10%|▉         | 67/682 [00:01<00:11, 55.19it/s]\u001b[A\u001b[A\n",
            "\n",
            " 11%|█         | 75/682 [00:01<00:10, 58.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 12%|█▏        | 82/682 [00:01<00:09, 61.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 13%|█▎        | 89/682 [00:01<00:09, 63.30it/s]\u001b[A\u001b[A\n",
            "\n",
            " 14%|█▍        | 96/682 [00:01<00:08, 65.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 15%|█▌        | 103/682 [00:01<00:08, 65.61it/s]\u001b[A\u001b[A\n",
            "\n",
            " 16%|█▌        | 110/682 [00:01<00:08, 65.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 17%|█▋        | 118/682 [00:01<00:08, 67.39it/s]\u001b[A\u001b[A\n",
            "\n",
            " 18%|█▊        | 125/682 [00:01<00:08, 67.35it/s]\u001b[A\u001b[A\n",
            "\n",
            " 20%|█▉        | 133/682 [00:02<00:07, 68.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 21%|██        | 140/682 [00:02<00:07, 68.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 22%|██▏       | 148/682 [00:02<00:07, 69.42it/s]\u001b[A\u001b[A\n",
            "\n",
            " 23%|██▎       | 155/682 [00:02<00:07, 69.22it/s]\u001b[A\u001b[A\n",
            "\n",
            " 24%|██▍       | 163/682 [00:02<00:07, 69.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 25%|██▍       | 170/682 [00:02<00:07, 68.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 26%|██▌       | 177/682 [00:02<00:07, 68.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 27%|██▋       | 184/682 [00:02<00:07, 67.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 28%|██▊       | 191/682 [00:02<00:07, 67.21it/s]\u001b[A\u001b[A\n",
            "\n",
            " 29%|██▉       | 199/682 [00:02<00:07, 68.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 30%|███       | 206/682 [00:03<00:07, 67.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 31%|███       | 213/682 [00:03<00:06, 68.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 32%|███▏      | 220/682 [00:03<00:06, 68.56it/s]\u001b[A\u001b[A\n",
            "\n",
            " 33%|███▎      | 227/682 [00:03<00:06, 68.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 34%|███▍      | 234/682 [00:03<00:06, 68.98it/s]\u001b[A\u001b[A\n",
            "\n",
            " 35%|███▌      | 241/682 [00:03<00:06, 68.26it/s]\u001b[A\u001b[A\n",
            "\n",
            " 36%|███▋      | 248/682 [00:03<00:06, 68.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 37%|███▋      | 255/682 [00:03<00:06, 67.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 38%|███▊      | 262/682 [00:03<00:06, 66.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 39%|███▉      | 269/682 [00:04<00:06, 67.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 40%|████      | 276/682 [00:04<00:05, 68.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 41%|████▏     | 283/682 [00:04<00:05, 67.99it/s]\u001b[A\u001b[A\n",
            "\n",
            " 43%|████▎     | 290/682 [00:04<00:05, 68.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 44%|████▎     | 297/682 [00:04<00:05, 68.29it/s]\u001b[A\u001b[A\n",
            "\n",
            " 45%|████▍     | 304/682 [00:04<00:05, 67.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 46%|████▌     | 311/682 [00:04<00:05, 66.41it/s]\u001b[A\u001b[A\n",
            "\n",
            " 47%|████▋     | 318/682 [00:04<00:05, 65.93it/s]\u001b[A\u001b[A\n",
            "\n",
            " 48%|████▊     | 325/682 [00:04<00:05, 65.36it/s]\u001b[A\u001b[A\n",
            "\n",
            " 49%|████▊     | 332/682 [00:04<00:05, 66.18it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50%|████▉     | 339/682 [00:05<00:05, 67.12it/s]\u001b[A\u001b[A\n",
            "\n",
            " 51%|█████     | 346/682 [00:05<00:04, 67.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 52%|█████▏    | 353/682 [00:05<00:04, 67.78it/s]\u001b[A\u001b[A\n",
            "\n",
            " 53%|█████▎    | 360/682 [00:05<00:04, 68.03it/s]\u001b[A\u001b[A\n",
            "\n",
            " 54%|█████▍    | 367/682 [00:05<00:04, 68.05it/s]\u001b[A\u001b[A\n",
            "\n",
            " 55%|█████▍    | 374/682 [00:05<00:04, 67.59it/s]\u001b[A\u001b[A\n",
            "\n",
            " 56%|█████▌    | 381/682 [00:05<00:04, 67.27it/s]\u001b[A\u001b[A\n",
            "\n",
            " 57%|█████▋    | 388/682 [00:05<00:04, 64.33it/s]\u001b[A\u001b[A\n",
            "\n",
            " 58%|█████▊    | 395/682 [00:05<00:04, 64.69it/s]\u001b[A\u001b[A\n",
            "\n",
            " 59%|█████▉    | 402/682 [00:06<00:04, 65.62it/s]\u001b[A\u001b[A\n",
            "\n",
            " 60%|█████▉    | 409/682 [00:06<00:04, 66.24it/s]\u001b[A\u001b[A\n",
            "\n",
            " 61%|██████    | 416/682 [00:06<00:03, 67.13it/s]\u001b[A\u001b[A\n",
            "\n",
            " 62%|██████▏   | 423/682 [00:06<00:03, 67.86it/s]\u001b[A\u001b[A\n",
            "\n",
            " 63%|██████▎   | 430/682 [00:06<00:03, 67.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 64%|██████▍   | 437/682 [00:06<00:03, 67.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 65%|██████▌   | 444/682 [00:06<00:03, 67.89it/s]\u001b[A\u001b[A\n",
            "\n",
            " 66%|██████▌   | 451/682 [00:06<00:03, 67.77it/s]\u001b[A\u001b[A\n",
            "\n",
            " 67%|██████▋   | 458/682 [00:06<00:03, 67.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 68%|██████▊   | 465/682 [00:06<00:03, 66.88it/s]\u001b[A\u001b[A\n",
            "\n",
            " 69%|██████▉   | 472/682 [00:07<00:03, 67.15it/s]\u001b[A\u001b[A\n",
            "\n",
            " 70%|███████   | 479/682 [00:07<00:03, 67.53it/s]\u001b[A\u001b[A\n",
            "\n",
            " 71%|███████▏  | 487/682 [00:07<00:02, 68.57it/s]\u001b[A\u001b[A\n",
            "\n",
            " 73%|███████▎  | 495/682 [00:07<00:02, 69.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 74%|███████▎  | 502/682 [00:07<00:02, 69.09it/s]\u001b[A\u001b[A\n",
            "\n",
            " 75%|███████▍  | 509/682 [00:07<00:02, 68.54it/s]\u001b[A\u001b[A\n",
            "\n",
            " 76%|███████▌  | 516/682 [00:07<00:02, 68.91it/s]\u001b[A\u001b[A\n",
            "\n",
            " 77%|███████▋  | 523/682 [00:07<00:02, 68.97it/s]\u001b[A\u001b[A\n",
            "\n",
            " 78%|███████▊  | 530/682 [00:07<00:02, 68.20it/s]\u001b[A\u001b[A\n",
            "\n",
            " 79%|███████▊  | 537/682 [00:07<00:02, 67.44it/s]\u001b[A\u001b[A\n",
            "\n",
            " 80%|███████▉  | 544/682 [00:08<00:02, 68.17it/s]\u001b[A\u001b[A\n",
            "\n",
            " 81%|████████  | 551/682 [00:08<00:01, 67.68it/s]\u001b[A\u001b[A\n",
            "\n",
            " 82%|████████▏ | 558/682 [00:08<00:01, 66.76it/s]\u001b[A\u001b[A\n",
            "\n",
            " 83%|████████▎ | 565/682 [00:08<00:01, 66.85it/s]\u001b[A\u001b[A\n",
            "\n",
            " 84%|████████▍ | 572/682 [00:08<00:01, 66.38it/s]\u001b[A\u001b[A\n",
            "\n",
            " 85%|████████▌ | 580/682 [00:08<00:01, 67.52it/s]\u001b[A\u001b[A\n",
            "\n",
            " 86%|████████▌ | 588/682 [00:08<00:01, 68.66it/s]\u001b[A\u001b[A\n",
            "\n",
            " 87%|████████▋ | 595/682 [00:08<00:01, 65.83it/s]\u001b[A\u001b[A\n",
            "\n",
            " 88%|████████▊ | 602/682 [00:08<00:01, 66.02it/s]\u001b[A\u001b[A\n",
            "\n",
            " 89%|████████▉ | 609/682 [00:09<00:01, 67.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 90%|█████████ | 616/682 [00:09<00:00, 67.67it/s]\u001b[A\u001b[A\n",
            "\n",
            " 91%|█████████▏| 623/682 [00:09<00:00, 68.04it/s]\u001b[A\u001b[A\n",
            "\n",
            " 92%|█████████▏| 630/682 [00:09<00:00, 68.32it/s]\u001b[A\u001b[A\n",
            "\n",
            " 93%|█████████▎| 637/682 [00:09<00:00, 68.07it/s]\u001b[A\u001b[A\n",
            "\n",
            " 94%|█████████▍| 644/682 [00:09<00:00, 67.63it/s]\u001b[A\u001b[A\n",
            "\n",
            " 95%|█████████▌| 651/682 [00:09<00:00, 67.48it/s]\u001b[A\u001b[A\n",
            "\n",
            " 96%|█████████▋| 658/682 [00:09<00:00, 67.92it/s]\u001b[A\u001b[A\n",
            "\n",
            " 98%|█████████▊| 665/682 [00:09<00:00, 65.81it/s]\u001b[A\u001b[A\n",
            "\n",
            " 99%|█████████▊| 672/682 [00:10<00:00, 65.04it/s]\u001b[A\u001b[A\n",
            "\n",
            "100%|██████████| 682/682 [00:10<00:00, 66.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYQHgkPlJt99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "317117c0-7b6e-443b-c184-4cce584af976"
      },
      "source": [
        "print(\"Pre-Processing of the outputs to generate the submision\")"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pre-Processing of the outputs to generate the submision\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBdNVuXH4_Wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "25e6669d-a231-49a2-8bda-7c5dfcd1a04d"
      },
      "source": [
        "print(axes)\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 1, 2, 3], [2, 2, 2, 3], [3, 2, 3, 3], [1, 3, 2, 2], [2, 1, 1, 2], [2, 2, 3, 3], [3, 2, 2, 3], [3, 3, 2, 2], [2, 2, 1, 3], [3, 1, 3, 3], [2, 3, 2, 2], [2, 2, 3, 2], [3, 2, 1, 2], [2, 3, 2, 2], [2, 2, 2, 2], [2, 2, 3, 2], [3, 2, 2, 3], [2, 2, 2, 3], [2, 2, 2, 2], [2, 2, 1, 2], [2, 2, 1, 2], [1, 3, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 3], [3, 2, 2, 3], [3, 2, 3, 3], [3, 2, 3, 3], [2, 2, 1, 3], [2, 2, 3, 2], [2, 2, 2, 1], [2, 2, 2, 1], [2, 3, 2, 3], [1, 1, 2, 1], [3, 2, 3, 3], [2, 2, 2, 3], [2, 2, 3, 2], [2, 2, 1, 2], [2, 2, 2, 1], [1, 2, 2, 2], [3, 3, 2, 3], [2, 2, 2, 2], [2, 2, 2, 2], [2, 3, 2, 3], [2, 2, 3, 2], [3, 2, 2, 2], [2, 3, 3, 2], [2, 2, 2, 1], [2, 3, 2, 3], [2, 3, 3, 2], [3, 2, 1, 2], [2, 1, 3, 3], [2, 1, 2, 2], [2, 3, 2, 3], [3, 3, 2, 2], [2, 2, 1, 2], [2, 2, 2, 2], [3, 2, 3, 2], [2, 2, 2, 3], [3, 2, 2, 2], [3, 2, 3, 3], [2, 2, 2, 2], [2, 3, 2, 2], [2, 3, 2, 2], [2, 2, 3, 2], [2, 3, 2, 2], [2, 3, 2, 2], [2, 3, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 3], [2, 2, 3, 2], [2, 2, 2, 3], [3, 2, 2, 2], [3, 3, 2, 2], [2, 2, 2, 2], [1, 3, 2, 3], [3, 2, 3, 2], [2, 2, 2, 3], [3, 2, 1, 2], [2, 2, 3, 3], [2, 2, 2, 2], [2, 2, 3, 2], [2, 3, 2, 1], [3, 2, 3, 3], [2, 3, 3, 2], [2, 3, 2, 2], [2, 3, 3, 2], [2, 2, 2, 3], [2, 2, 2, 2], [3, 2, 3, 1], [3, 3, 2, 3], [2, 2, 2, 2], [2, 2, 2, 2], [3, 3, 2, 2], [2, 3, 2, 2], [2, 1, 2, 3], [3, 2, 3, 2], [2, 2, 3, 2], [2, 2, 2, 2], [2, 2, 2, 2], [3, 2, 2, 2], [2, 2, 2, 2], [3, 1, 2, 3], [2, 2, 3, 2], [1, 3, 3, 2], [2, 2, 2, 3], [2, 2, 2, 2], [2, 2, 3, 2], [3, 2, 2, 3], [3, 3, 2, 2], [2, 2, 2, 3], [3, 2, 3, 3], [2, 2, 3, 2], [2, 2, 3, 3], [2, 3, 2, 2], [1, 2, 2, 2], [2, 1, 2, 3], [2, 2, 2, 2], [2, 3, 2, 2], [3, 3, 2, 3], [2, 2, 3, 2], [2, 2, 2, 2], [2, 2, 2, 2], [3, 2, 2, 2], [2, 2, 3, 2], [2, 2, 1, 3], [3, 2, 3, 2], [2, 2, 3, 3], [2, 3, 3, 3], [2, 2, 1, 3], [2, 3, 2, 3], [3, 3, 2, 2], [3, 2, 2, 3], [3, 2, 3, 2], [3, 3, 3, 3], [2, 2, 2, 2], [2, 2, 3, 1], [3, 2, 2, 2], [3, 3, 2, 3], [2, 2, 2, 3], [2, 2, 2, 2], [2, 2, 2, 3], [2, 2, 1, 2], [2, 2, 2, 2], [2, 2, 2, 2], [3, 2, 1, 2], [2, 2, 2, 2], [2, 2, 2, 1], [1, 3, 2, 2], [2, 3, 2, 2], [2, 2, 3, 2], [3, 2, 2, 3], [2, 2, 3, 2], [2, 3, 2, 2], [2, 3, 3, 2], [2, 3, 3, 2], [3, 2, 2, 2], [2, 2, 2, 3], [2, 1, 2, 2], [2, 2, 2, 1], [2, 2, 2, 2], [2, 2, 3, 2], [2, 2, 3, 2], [2, 3, 2, 2], [2, 2, 2, 3], [2, 3, 2, 1], [1, 2, 2, 2], [2, 2, 1, 3], [2, 3, 2, 2], [2, 2, 2, 2], [1, 2, 2, 2], [2, 2, 3, 2], [2, 3, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [1, 2, 2, 3], [1, 3, 1, 3], [2, 2, 3, 3], [3, 2, 2, 2], [2, 2, 1, 2], [2, 2, 3, 2], [2, 2, 2, 2], [3, 3, 2, 3], [3, 3, 2, 3], [2, 3, 2, 2], [2, 3, 2, 1], [3, 3, 2, 2], [2, 2, 3, 3], [2, 2, 2, 2], [2, 3, 2, 2], [2, 2, 2, 2], [2, 2, 3, 2], [2, 3, 2, 2], [2, 1, 3, 2], [3, 3, 2, 3], [2, 2, 2, 2], [2, 2, 2, 3], [2, 1, 3, 2], [1, 2, 3, 2], [2, 3, 2, 3], [1, 3, 2, 3], [2, 2, 3, 2], [2, 3, 2, 3], [3, 2, 3, 2], [3, 2, 3, 2], [3, 3, 2, 2], [3, 2, 3, 2], [3, 2, 2, 3], [1, 2, 3, 3], [2, 3, 2, 1], [1, 3, 1, 2], [2, 3, 2, 1], [2, 3, 3, 2], [2, 2, 2, 3], [2, 1, 2, 2], [3, 2, 2, 3], [3, 3, 2, 2], [2, 2, 3, 2], [2, 2, 3, 2], [2, 3, 2, 3], [2, 3, 3, 2], [3, 2, 3, 3], [2, 3, 2, 3], [2, 2, 2, 2], [3, 2, 2, 2], [2, 2, 2, 2], [2, 3, 2, 2], [2, 3, 2, 2], [3, 2, 3, 1], [3, 2, 2, 2], [2, 2, 2, 1], [2, 3, 3, 3], [2, 3, 2, 3], [3, 2, 3, 3], [2, 2, 3, 3], [2, 1, 3, 2], [2, 2, 2, 2], [3, 3, 3, 2], [3, 2, 2, 2], [2, 2, 2, 1], [3, 2, 3, 2], [2, 2, 3, 3], [2, 3, 2, 3], [3, 2, 2, 2], [2, 2, 2, 3], [3, 2, 1, 2], [2, 2, 2, 2], [2, 2, 2, 3], [2, 3, 2, 1], [3, 2, 2, 3], [2, 3, 2, 2], [3, 3, 3, 1], [2, 3, 3, 2], [2, 2, 2, 3], [2, 2, 2, 3], [2, 3, 2, 3], [2, 3, 2, 3], [1, 1, 2, 2], [2, 3, 2, 3], [2, 3, 3, 2], [3, 2, 1, 2], [3, 2, 2, 2], [2, 2, 2, 3], [3, 2, 2, 1], [3, 2, 2, 3], [1, 3, 1, 3], [3, 2, 3, 2], [3, 2, 2, 2], [2, 2, 3, 2], [2, 3, 3, 2], [2, 2, 3, 3], [2, 2, 2, 3], [3, 3, 2, 2], [2, 2, 2, 2], [2, 2, 3, 2], [3, 3, 1, 3], [1, 3, 3, 2], [2, 3, 1, 3], [2, 2, 2, 2], [2, 2, 2, 2], [2, 3, 2, 3], [2, 2, 2, 3], [2, 2, 2, 3], [2, 1, 2, 3], [1, 2, 3, 2], [2, 2, 3, 2], [2, 3, 2, 3], [2, 2, 3, 3], [2, 2, 2, 2], [3, 3, 2, 3], [2, 2, 3, 2], [0, 3, 3, 3], [3, 2, 2, 3], [2, 3, 2, 2], [2, 2, 2, 2], [2, 3, 2, 2], [2, 2, 3, 2], [2, 3, 2, 2], [2, 1, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [1, 2, 2, 2], [3, 3, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 3, 2], [2, 2, 2, 3], [2, 3, 3, 3], [3, 2, 2, 2], [3, 2, 2, 2], [2, 2, 3, 2], [3, 2, 1, 2], [3, 2, 3, 3], [3, 2, 2, 3], [2, 2, 2, 3], [2, 2, 3, 3], [3, 2, 3, 2], [2, 2, 2, 3], [3, 3, 2, 2], [2, 2, 3, 3], [3, 3, 3, 2], [2, 3, 2, 2], [2, 2, 2, 3], [1, 2, 2, 2], [2, 2, 2, 3], [2, 3, 2, 3], [3, 2, 1, 2], [3, 2, 2, 3], [2, 2, 2, 2], [1, 2, 2, 2], [3, 2, 2, 2], [2, 2, 2, 1], [3, 2, 2, 3], [2, 2, 2, 2], [3, 2, 2, 3], [3, 2, 1, 2], [3, 2, 3, 2], [3, 2, 3, 3], [3, 3, 2, 3], [2, 3, 2, 2], [1, 2, 2, 2], [3, 3, 2, 2], [3, 2, 1, 2], [3, 1, 2, 2], [2, 2, 3, 2], [2, 3, 1, 3], [2, 3, 2, 2], [1, 2, 2, 1], [2, 2, 2, 2], [2, 3, 3, 2], [2, 2, 1, 3], [2, 3, 3, 3], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [3, 2, 2, 2], [2, 2, 2, 2], [2, 2, 1, 1], [3, 3, 1, 3], [2, 2, 3, 2], [2, 2, 2, 2], [2, 3, 2, 3], [1, 2, 2, 2], [2, 3, 3, 1], [2, 2, 3, 2], [3, 2, 2, 2], [2, 2, 2, 2], [3, 1, 2, 3], [2, 3, 2, 3], [2, 1, 3, 2], [2, 2, 2, 2], [3, 2, 2, 2], [2, 2, 3, 3], [3, 1, 2, 2], [1, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 3, 3, 2], [2, 3, 2, 2], [2, 3, 2, 1], [2, 3, 3, 1], [2, 2, 2, 2], [2, 2, 2, 2], [1, 1, 2, 3], [3, 2, 2, 3], [2, 3, 2, 2], [2, 2, 2, 2], [3, 2, 3, 2], [3, 3, 2, 2], [2, 2, 3, 1], [2, 1, 3, 2], [3, 3, 3, 2], [3, 3, 3, 3], [1, 2, 2, 3], [2, 2, 1, 2], [2, 2, 2, 2], [2, 1, 2, 3], [2, 2, 3, 2], [1, 2, 2, 2], [3, 1, 1, 2], [3, 3, 2, 2], [3, 2, 2, 3], [2, 3, 2, 2], [3, 2, 3, 2], [2, 3, 2, 2], [2, 3, 3, 3], [3, 2, 2, 1], [1, 2, 2, 2], [3, 2, 1, 3], [2, 3, 3, 3], [2, 2, 2, 2], [2, 2, 2, 3], [3, 2, 2, 2], [3, 2, 2, 3], [3, 2, 3, 3], [2, 2, 3, 2], [3, 2, 3, 2], [3, 2, 2, 2], [2, 2, 2, 1], [2, 2, 2, 2], [2, 3, 2, 3], [2, 3, 2, 2], [3, 3, 3, 3], [3, 3, 2, 2], [3, 2, 3, 3], [2, 2, 2, 2], [2, 2, 3, 2], [2, 2, 3, 1], [1, 3, 3, 2], [2, 2, 2, 2], [2, 2, 2, 3], [2, 2, 2, 2], [1, 2, 2, 2], [2, 3, 3, 2], [2, 2, 2, 3], [3, 2, 2, 3], [3, 2, 2, 3], [2, 2, 2, 2], [2, 1, 2, 3], [2, 2, 2, 3], [2, 2, 2, 2], [2, 1, 3, 2], [2, 2, 3, 2], [1, 2, 2, 2], [2, 1, 2, 1], [2, 3, 2, 2], [3, 3, 2, 2], [2, 3, 3, 2], [3, 2, 3, 1], [2, 2, 3, 2], [2, 2, 2, 2], [3, 2, 3, 2], [2, 3, 2, 2], [3, 2, 2, 2], [2, 3, 2, 3], [2, 2, 3, 2], [2, 2, 3, 3], [3, 2, 3, 3], [2, 2, 2, 2], [2, 3, 2, 2], [3, 3, 2, 3], [1, 2, 2, 2], [2, 2, 3, 2], [2, 2, 2, 2], [2, 2, 3, 3], [1, 2, 2, 3], [3, 2, 3, 2], [3, 2, 1, 3], [2, 2, 1, 3], [2, 2, 1, 3], [2, 2, 3, 3], [1, 3, 3, 3], [2, 2, 2, 3], [2, 2, 2, 3], [2, 2, 1, 3], [3, 2, 2, 2], [2, 2, 2, 2], [3, 2, 2, 2], [3, 2, 2, 2], [3, 3, 2, 2], [2, 2, 2, 3], [2, 2, 2, 3], [2, 3, 3, 2], [2, 2, 2, 2], [2, 3, 3, 2], [2, 3, 1, 2], [2, 2, 3, 2], [3, 2, 2, 2], [1, 3, 1, 2], [2, 2, 2, 3], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 1, 2], [2, 2, 1, 3], [3, 1, 3, 3], [3, 2, 2, 3], [1, 2, 3, 2], [3, 2, 2, 2], [1, 3, 2, 3], [2, 3, 2, 2], [2, 2, 3, 3], [2, 2, 2, 2], [2, 2, 2, 2], [3, 2, 3, 2], [3, 2, 2, 2], [2, 3, 2, 2], [3, 2, 2, 2], [2, 3, 2, 2], [1, 2, 2, 2], [2, 3, 3, 2], [2, 2, 2, 2], [2, 2, 2, 2], [2, 3, 1, 1], [2, 2, 2, 3], [2, 2, 3, 2], [3, 3, 2, 2], [3, 2, 2, 3], [2, 1, 2, 2], [1, 3, 2, 2], [3, 2, 2, 2], [2, 3, 2, 2], [1, 2, 2, 2], [2, 2, 2, 3], [3, 3, 3, 3], [2, 1, 3, 2], [2, 1, 3, 3], [2, 2, 1, 2], [3, 2, 1, 3], [3, 2, 2, 2], [2, 3, 2, 2], [2, 2, 2, 2], [3, 2, 2, 2], [3, 2, 2, 2], [3, 3, 2, 3], [2, 3, 2, 3], [3, 3, 2, 2], [2, 3, 2, 1], [2, 3, 1, 2], [2, 3, 2, 2], [2, 2, 2, 3], [2, 3, 2, 2], [2, 2, 2, 3], [2, 2, 2, 1], [2, 3, 3, 2], [2, 3, 3, 2], [3, 3, 2, 2], [3, 3, 2, 2], [2, 2, 2, 2], [2, 2, 3, 2], [2, 2, 2, 2], [2, 2, 3, 3], [2, 2, 2, 2], [3, 2, 3, 3], [2, 2, 2, 3], [2, 2, 2, 2], [1, 3, 2, 3], [2, 2, 2, 3], [3, 2, 2, 2], [2, 2, 3, 2], [2, 3, 2, 3], [2, 2, 3, 2], [2, 2, 2, 2], [2, 3, 2, 3], [2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 1, 2], [3, 3, 3, 2], [3, 3, 2, 2], [2, 3, 2, 2], [2, 2, 2, 2], [3, 2, 3, 2], [3, 3, 2, 1], [2, 3, 2, 3], [2, 2, 2, 2], [2, 2, 3, 2], [2, 2, 3, 2], [2, 2, 2, 3], [2, 2, 3, 2], [2, 2, 2, 3], [2, 2, 3, 2], [3, 2, 2, 2], [2, 3, 3, 2], [2, 2, 3, 2], [3, 2, 1, 2], [2, 2, 2, 2], [3, 2, 2, 2], [2, 2, 1, 2], [2, 2, 2, 2], [2, 3, 3, 3], [3, 2, 2, 1], [2, 3, 2, 2], [2, 2, 2, 2], [2, 2, 2, 3], [1, 3, 2, 3], [3, 2, 3, 2], [2, 2, 2, 3], [2, 2, 3, 1], [2, 3, 3, 3], [2, 2, 2, 3], [3, 1, 2, 2], [2, 1, 2, 2], [2, 2, 2, 2], [2, 3, 2, 2], [2, 2, 2, 2], [3, 1, 2, 3], [3, 2, 2, 3], [3, 2, 2, 2], [2, 2, 1, 1], [3, 2, 3, 3], [3, 2, 3, 2], [2, 2, 2, 3], [3, 3, 3, 2], [2, 3, 1, 3], [2, 1, 1, 2], [2, 2, 3, 2], [2, 3, 2, 2], [2, 1, 3, 2], [3, 2, 3, 2], [2, 2, 2, 2], [2, 1, 2, 2], [2, 3, 3, 3], [2, 3, 2, 2], [2, 2, 2, 2], [2, 2, 2, 3], [2, 1, 2, 3], [3, 2, 2, 2], [2, 2, 2, 3], [3, 3, 2, 3], [3, 1, 3, 2], [2, 3, 2, 3], [1, 2, 2, 3], [2, 3, 2, 2], [3, 2, 2, 2], [2, 2, 2, 3], [2, 2, 2, 1], [3, 2, 2, 3], [2, 2, 3, 2], [3, 2, 3, 2], [2, 1, 2, 3], [3, 2, 1, 3], [3, 3, 3, 2], [2, 3, 2, 2], [2, 2, 2, 3], [2, 2, 2, 3], [3, 3, 3, 1], [3, 3, 2, 3], [2, 1, 2, 2], [3, 2, 2, 3], [2, 3, 2, 1], [2, 2, 2, 2], [2, 3, 2, 3], [2, 2, 3, 2], [1, 2, 3, 1], [2, 2, 2, 2], [2, 2, 2, 3], [1, 2, 2, 2], [3, 3, 2, 3], [3, 2, 2, 2], [3, 2, 2, 2], [3, 3, 1, 2], [2, 3, 2, 3], [3, 2, 2, 2], [2, 3, 2, 3], [2, 2, 1, 3], [3, 3, 2, 3], [3, 3, 3, 3], [3, 2, 3, 2], [2, 2, 3, 1], [2, 2, 2, 3], [2, 2, 2, 3], [2, 3, 2, 2], [2, 2, 2, 3], [2, 3, 2, 3], [3, 2, 2, 3], [2, 3, 2, 3], [2, 3, 2, 3], [3, 2, 2, 2], [2, 3, 2, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUC1-WKh6Gys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# aha this seems some Good predictions as compared to the previous predictions where the model predicted class2 always\n",
        "# We are going to fill in the Classes for the test Dataframe , if want you can use the probablities"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC8Q9nyaDM5o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "46323853-da57-44f1-ed17-7508f1aeab39"
      },
      "source": [
        "senti = []\n",
        "for i in axes:\n",
        "    senti.extend(i)\n",
        "print(senti)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 1, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 1, 3, 2, 2, 2, 1, 1, 2, 2, 2, 3, 3, 3, 2, 2, 3, 3, 3, 2, 2, 2, 2, 1, 3, 3, 1, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 3, 2, 1, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 3, 3, 3, 2, 3, 3, 2, 2, 1, 3, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 3, 2, 3, 1, 1, 2, 1, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 2, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 1, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 1, 2, 2, 1, 3, 3, 2, 1, 2, 2, 2, 3, 2, 3, 3, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 1, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 1, 3, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 1, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 1, 2, 3, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 2, 2, 3, 2, 1, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 2, 2, 1, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 3, 3, 2, 3, 2, 2, 2, 3, 3, 2, 3, 3, 3, 2, 2, 1, 3, 2, 3, 2, 3, 3, 3, 2, 2, 3, 2, 2, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 1, 3, 2, 2, 2, 3, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 1, 1, 2, 2, 2, 2, 2, 1, 3, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 3, 1, 3, 1, 3, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3, 2, 3, 3, 3, 2, 3, 2, 3, 2, 2, 2, 3, 2, 1, 3, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 1, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 3, 2, 1, 2, 3, 2, 2, 3, 2, 3, 1, 3, 2, 3, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 1, 2, 3, 3, 2, 3, 2, 1, 1, 3, 1, 2, 2, 3, 2, 1, 2, 3, 3, 2, 2, 2, 2, 3, 2, 1, 2, 2, 3, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 1, 3, 2, 2, 2, 2, 2, 2, 1, 2, 3, 3, 3, 2, 3, 2, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 1, 3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 1, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 3, 1, 2, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 1, 1, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 1, 3, 2, 2, 3, 1, 3, 1, 3, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 3, 3, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 1, 3, 1, 3, 3, 2, 2, 3, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 2, 2, 3, 2, 0, 3, 3, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 1, 2, 3, 2, 3, 3, 3, 2, 2, 3, 2, 2, 2, 3, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 1, 2, 3, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 1, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 1, 2, 3, 2, 3, 2, 3, 2, 3, 3, 3, 3, 2, 3, 2, 3, 2, 2, 1, 2, 2, 2, 3, 3, 2, 2, 3, 2, 1, 2, 3, 1, 2, 2, 2, 2, 3, 2, 2, 3, 1, 3, 2, 3, 2, 2, 1, 2, 2, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 1, 3, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 3, 3, 1, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 1, 2, 2, 2, 2, 3, 3, 1, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 2, 3, 2, 3, 2, 1, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 3, 3, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 3, 2, 1, 2, 3, 3, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 2, 3, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 2, 2, 2, 3, 1, 2, 1, 3, 2, 3, 3, 3, 2, 3, 3, 3, 3, 1, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 3, 2, 1, 2, 2, 2, 3, 1, 1, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 3, 3, 3, 3, 2, 2, 1, 1, 2, 2, 2, 3, 2, 1, 3, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 3, 3, 3, 3, 3, 3, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 1, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 3, 2, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 3, 2, 2, 2, 3, 2, 1, 2, 2, 2, 2, 1, 2, 1, 2, 3, 2, 2, 3, 3, 2, 2, 2, 3, 3, 2, 3, 2, 3, 1, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 3, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 2, 2, 3, 3, 2, 3, 2, 3, 2, 1, 3, 2, 2, 1, 3, 2, 2, 1, 3, 2, 2, 3, 3, 1, 3, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 1, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 1, 2, 2, 2, 3, 2, 3, 2, 2, 2, 1, 3, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 3, 3, 1, 3, 3, 3, 2, 2, 3, 1, 2, 3, 2, 3, 2, 2, 2, 1, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 1, 2, 2, 2, 3, 2, 2, 3, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 1, 2, 2, 1, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 1, 3, 2, 2, 1, 3, 3, 2, 2, 1, 2, 3, 2, 1, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 3, 3, 2, 3, 2, 3, 2, 3, 3, 3, 2, 2, 2, 3, 2, 1, 2, 3, 1, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 3, 3, 2, 2, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 1, 3, 2, 3, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 3, 3, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 1, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 2, 2, 2, 3, 2, 3, 2, 1, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 1, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 3, 2, 2, 3, 1, 2, 3, 3, 3, 2, 2, 2, 3, 3, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 1, 2, 3, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 1, 1, 3, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 3, 1, 3, 2, 1, 1, 2, 2, 2, 3, 2, 2, 3, 2, 2, 2, 1, 3, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1, 2, 3, 3, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 1, 3, 2, 2, 3, 2, 3, 1, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 3, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 2, 2, 1, 2, 3, 3, 2, 1, 3, 3, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 3, 3, 1, 3, 3, 2, 3, 2, 1, 2, 2, 3, 2, 2, 3, 2, 3, 2, 1, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 1, 2, 3, 1, 2, 2, 2, 2, 2, 2, 2, 3, 1, 2, 2, 2, 3, 3, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 3, 1, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 3, 2, 3, 2, 2, 1, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 2, 3, 2, 2, 2, 3, 1, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 2, 2, 2, 2, 3, 2, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpW-5p3fHoaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(senti) \n"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b67edw2HzUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[\"sentiment\"] = df"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWp-bckdIEfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "433e2642-923c-410c-8d43-ff86850462dd"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>Product_Type</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5786</td>\n",
              "      <td>7</td>\n",
              "      <td>RT mention Going to SXSW The new iPhone guide ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5363</td>\n",
              "      <td>9</td>\n",
              "      <td>RT mention 95 of iPhone and Droid apps have le...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6716</td>\n",
              "      <td>9</td>\n",
              "      <td>RT mention Thank you to mention for letting me...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4339</td>\n",
              "      <td>7</td>\n",
              "      <td>Thanks mention were lovin the mention app upda...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>66</td>\n",
              "      <td>9</td>\n",
              "      <td>At sxsw mention  mention wanna buy you a drink...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Text_ID  ...  sentiment\n",
              "0     5786  ...          3\n",
              "1     5363  ...          1\n",
              "2     6716  ...          2\n",
              "3     4339  ...          3\n",
              "4       66  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzWknWicIXiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.drop(\"Product_Type\",axis=1,inplace=True)\n",
        "test.to_csv('submission1.csv') \n"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzYeAJScI5XV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = pd.read_csv(\"/content/submission1.csv\")"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuOXLHpPJBKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "8a51ab14-c83c-4337-ab32-2e77bd8fbe5c"
      },
      "source": [
        "test_pred.head(10)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text_ID</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5786</td>\n",
              "      <td>RT mention Going to SXSW The new iPhone guide ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5363</td>\n",
              "      <td>RT mention 95 of iPhone and Droid apps have le...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6716</td>\n",
              "      <td>RT mention Thank you to mention for letting me...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>4339</td>\n",
              "      <td>Thanks mention were lovin the mention app upda...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>66</td>\n",
              "      <td>At sxsw mention  mention wanna buy you a drink...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>8373</td>\n",
              "      <td>I just rated GSDampM Idea City LLC 5 stars men...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>4264</td>\n",
              "      <td>mention Making new fans and friends I hope RT ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>1982</td>\n",
              "      <td>Want a chance to win an iPad 2 while youre at ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>2258</td>\n",
              "      <td>mention be sure to use our FREE App for checki...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>8828</td>\n",
              "      <td>Free SXSW music sampler on itunes Includes men...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  sentiment\n",
              "0           0  ...          3\n",
              "1           1  ...          1\n",
              "2           2  ...          2\n",
              "3           3  ...          3\n",
              "4           4  ...          2\n",
              "5           5  ...          2\n",
              "6           6  ...          2\n",
              "7           7  ...          3\n",
              "8           8  ...          3\n",
              "9           9  ...          2\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz9iVo3aJEbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "7a3d6746-0ab5-4203-c48d-5768714f72bc"
      },
      "source": [
        "sns.countplot(test_pred[\"sentiment\"])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5c54bc64a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG3IN4EpJKHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}